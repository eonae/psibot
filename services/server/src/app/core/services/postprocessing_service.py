"""
–°–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è.
"""

import logging
import re
from pathlib import Path
from typing import List

from src.app.core.models import (
    MergedTranscriptionResult,
    SegmentCollection,
    TranscriptionSegmentWithSpeaker,
)
from src.app.core.ports import FileStorage
from src.app.core.ports.ml import Gpt
from src.shared.logging import log_time

logger = logging.getLogger(__name__)

# pylint: disable=line-too-long
# flake8: noqa: E501
PROMPT_TEMPLATE = """
    –¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Å–∏—Ö–æ–ª–æ–≥. –ù–∞ –≤—Ö–æ–¥ —Ç–µ–±–µ –¥–∞—ë—Ç—Å—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
    –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏ –ø—Å–∏—Ö–æ–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —Å–µ—Å—Å–∏–∏. –û–¥–∏–Ω –∏–∑ –≥–æ–≤–æ—Ä—è—â–∏—Ö ‚Äî —Ç–µ—Ä–∞–ø–µ–≤—Ç, –¥—Ä—É–≥–æ–π ‚Äî –∫–ª–∏–µ–Ω—Ç.

    –¢–≤–æ–∏ –∑–∞–¥–∞—á–∏:

    1. –û–±—ä–µ–¥–∏–Ω—è–π –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ —Ä–µ–ø–ª–∏–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏:
    - –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç –æ–¥–Ω–æ–º—É –∏ —Ç–æ–º—É –∂–µ –≥–æ–≤–æ—Ä—è—â–µ–º—É;
    - —è–≤–Ω–æ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è;
    - —Å–ª–µ–¥–∏ –∑–∞ —Ç–µ–º, —á—Ç–æ–±—ã –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–µ —Ä–µ–ø–ª–∏–∫–∏ –±—ã–ª–∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º–∏.

    2. –ü—Ä–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–∏ –±–µ—Ä–∏ –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è

    3. –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π —Ç–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä–∏ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–π —Ä–µ–ø–ª–∏–∫–∏:
    - –†–∞–∑–±–µ–π —á—Ä–µ–∑–º–µ—Ä–Ω–æ –¥–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è;
    - –ü–æ—Å—Ç–∞–≤—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è;

    –ü—Ä–∏–∑–Ω–∞–∫–∏ —Ä–æ–ª–µ–π:

    –¢–µ—Ä–∞–ø–µ–≤—Ç:
    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –≤—Ä–æ–¥–µ: "—è –¥—É–º–∞—é", "–ø–æ—Ö–æ–∂–µ", "–≤–∞–º —Ç—è–∂–µ–ª–æ", "–≤—ã —á—É–≤—Å—Ç–≤—É–µ—Ç–µ"
    - –ß–∞—Å—Ç–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç, –æ—Ç—Ä–∞–∂–∞–µ—Ç —ç–º–æ—Ü–∏–∏
    - –í –æ—Å–Ω–æ–≤–Ω–æ–º –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–µ—Ç —Å–ª–æ–≤–∞ –∫–ª–∏–µ–Ω—Ç–∞

    –ö–ª–∏–µ–Ω—Ç:
    - –ì–æ–≤–æ—Ä–∏—Ç –æ —Å–µ–±–µ: "—è —á—É–≤—Å—Ç–≤—É—é", "–º–Ω–µ –∫–∞–∂–µ—Ç—Å—è", "—è —Å–∫–∞–∑–∞–ª", "—è –∑–∞–º–µ—Ç–∏–ª–∞"
    - –î–µ–ª–∏—Ç—Å—è –ª–∏—á–Ω—ã–º–∏ –ø–µ—Ä–µ–∂–∏–≤–∞–Ω–∏—è–º–∏, –æ–ø–∏—Å—ã–≤–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏—è, –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è

    –ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–∞:

    0 [SPEAKER_01] –º–Ω–µ –∫–∞–∂–µ—Ç—Å—è —è —Å–ª–∏—à–∫–æ–º –æ—Å—Ç—Ä–æ —Ä–µ–∞–≥–∏—Ä—É—é –Ω–∞ –∫—Ä–∏—Ç–∏–∫—É
    1 [SPEAKER_01] –ø–æ—Ç–æ–º –≤–µ—Å—å –¥–µ–Ω—å —Ö–æ–∂—É –∏ –ø—Ä–æ–∫—Ä—É—á–∏–≤–∞—é —ç—Ç–æ –≤ –≥–æ–ª–æ–≤–µ
    2 [SPEAKER_00] –∑–≤—É—á–∏—Ç —Ç–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ –∫—Ä–∏—Ç–∏–∫—É –∞ –ø—Ä–æ —Ç–æ –∫–∞–∫ –≤—ã –µ—ë –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞–µ—Ç–µ
    3 [SPEAKER_00] –∫–∞–∫ –±—É–¥—Ç–æ –æ–Ω–∞ –≤–∞—Å –∑–∞–¥–µ–≤–∞–µ—Ç –≥–ª—É–±–∂–µ —á–µ–º –ø—Ä–æ—Å—Ç–æ –∑–∞–º–µ—á–∞–Ω–∏–µ

    –†–µ–∑—É–ª—å—Ç–∞—Ç:

    0 [SPEAKER_01] –ú–Ω–µ –∫–∞–∂–µ—Ç—Å—è, —è —Å–ª–∏—à–∫–æ–º –æ—Å—Ç—Ä–æ —Ä–µ–∞–≥–∏—Ä—É—é –Ω–∞ –∫—Ä–∏—Ç–∏–∫—É. –ü–æ—Ç–æ–º –≤–µ—Å—å –¥–µ–Ω—å —Ö–æ–∂—É –∏ –ø—Ä–æ–∫—Ä—É—á–∏–≤–∞—é —ç—Ç–æ –≤ –≥–æ–ª–æ–≤–µ.
    1 [SPEAKER_00] –ó–≤—É—á–∏—Ç —Ç–∞–∫, –±—É–¥—Ç–æ —ç—Ç–æ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ –∫—Ä–∏—Ç–∏–∫—É, –∞ –ø—Ä–æ —Ç–æ, –∫–∞–∫ –≤—ã –µ—ë –≤–æ—Å–ø—Ä–∏–Ω–∏–º–∞–µ—Ç–µ. –ö–∞–∫ –±—É–¥—Ç–æ –æ–Ω–∞ –∑–∞–¥–µ–≤–∞–µ—Ç –≤–∞—Å –≥–ª—É–±–∂–µ, —á–µ–º –ø—Ä–æ—Å—Ç–æ –∑–∞–º–µ—á–∞–Ω–∏–µ.

    {text}
"""


class PostprocessingService:
    """
    –°–µ—Ä–≤–∏—Å –¥–ª—è –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ø—Ä–∏ –ø–æ–º–æ—â–∏ GPT.
    """

    def __init__(self, storage: FileStorage, gpt: Gpt):
        self.storage = storage
        self.gpt = gpt

    def postprocess(self, source_filename: Path, target_filename: Path) -> None:
        """–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

        Args:
            source_filename: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            target_filename: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        """
        logger.info("üéØ Starting post-processing of %s...", source_filename)

        text_data = self.storage.read(Path(source_filename)).decode()
        parsed_data = SegmentCollection.parse(
            text_data, TranscriptionSegmentWithSpeaker
        )

        transformed_results = self._transform(parsed_data)

        self.storage.save(str(transformed_results).encode(), Path(target_filename))

        logger.info("‚úÖ Post-processing completed: %s", target_filename)

    @log_time
    def _transform(
        self, results: MergedTranscriptionResult
    ) -> MergedTranscriptionResult:
        """–ü–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        """

        transformed_chunks: List[MergedTranscriptionResult] = []

        chunks = results.split(self.gpt.MAX_SYMBOLS)

        for i, chunk in enumerate(chunks):
            logger.info("Processing chunk %d of %d", i + 1, len(chunks))
            # –ó–∞–º–µ–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ä
            text = "\n".join([f"{i} {str(line)}" for i, line in enumerate(chunk)])
            prompt = PROMPT_TEMPLATE.format(text=text)
            logger.debug("Prompt for chunk %d:\n %s", i + 1, prompt)

            response = self.gpt.reply(prompt)
            logger.debug("GPT Response for chunk %d:\n %s", i + 1, response)

            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤ –æ—Ç–≤–µ—Ç–µ
            transformed_chunk: SegmentCollection[TranscriptionSegmentWithSpeaker] = (
                SegmentCollection()
            )

            lines = [line for line in response.split("\n") if line]

            for i, line in enumerate(lines):
                # –ü–∞—Ä—Å–∏–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏, —Å–ø–∏–∫–µ—Ä–∞ –∏ —Ç–µ–∫—Å—Ç
                pattern = r"(\d+)\s+\[(.*?)\]\s+(.*)"
                match = re.match(pattern, line)
                if not match:
                    continue

                line_number = int(match.group(1))
                speaker = match.group(2)
                text = match.group(3)

                # –ù–∞—Ö–æ–¥–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Å–µ–≥–º–µ–Ω—Ç –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                if line_number >= len(chunk):
                    logger.warning(
                        "Line number %d is out of range (chunk size: %d)",
                        line_number,
                        len(chunk),
                    )
                    continue

                original_segment = chunk[line_number]

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º end –≤—Ä–µ–º—è
                if i < len(lines) - 1:
                    next_line = lines[i + 1]
                    next_match = re.match(pattern, next_line)
                    if next_match:
                        next_line_number = int(next_match.group(1))
                        if next_line_number >= len(chunk):
                            end_time = original_segment.end
                        else:
                            end_segment = chunk[next_line_number]
                            end_time = end_segment.start
                    else:
                        end_time = original_segment.end
                else:
                    end_time = original_segment.end

                # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å–µ–≥–º–µ–Ω—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –≤—Ä–µ–º–µ–Ω–∞–º–∏
                new_segment = TranscriptionSegmentWithSpeaker(
                    start=original_segment.start,
                    end=end_time,
                    speaker=speaker,
                    text=text,
                )

                transformed_chunk.append(new_segment)

            transformed_chunks.append(transformed_chunk)

        return SegmentCollection(
            [segment for chunk in transformed_chunks for segment in chunk]
        )
